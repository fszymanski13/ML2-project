{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"data/r2.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_chlorides = list(df['chlorides'].quantile([0, 0.25, 0.5, 0.75, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "df['chlorides'] = pd.cut(df['chlorides'], bins=quantiles_chlorides, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1    356\n",
       "Q3    355\n",
       "Q2    347\n",
       "Q4    342\n",
       "Name: chlorides, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chlorides'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_residual_sugar = list(df['residual sugar'].quantile([0, 0.25, 0.5, 0.75, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "df['residual sugar'] = pd.cut(df['residual sugar'], bins=quantiles_residual_sugar, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_sulphates = list(df['sulphates'].quantile([0, 0.25, 0.5, 0.75, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "df['sulphates'] = pd.cut(df['sulphates'], bins=quantiles_sulphates, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['quality', 'id'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "cols_to_scale = X_train.columns.drop(['chlorides', 'residual sugar', 'sulphates'])\n",
    "cols_to_encode = ['chlorides', 'residual sugar', 'sulphates']\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "categoric_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_to_scale),\n",
    "        ('cat', categoric_transformer, cols_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "columns = cols_to_scale.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out(cols_to_encode).tolist()\n",
    "X_train = pd.DataFrame(X_train, columns=columns)\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, X_val, y_train_sample, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Val_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Val_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.252533</td>\n",
       "      <td>0.238291</td>\n",
       "      <td>16.569106</td>\n",
       "      <td>17.485227</td>\n",
       "      <td>1.06063</td>\n",
       "      <td>1.152173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Linear Regression</th>\n",
       "      <td>0.257351</td>\n",
       "      <td>0.242384</td>\n",
       "      <td>16.64001</td>\n",
       "      <td>17.588544</td>\n",
       "      <td>1.057206</td>\n",
       "      <td>1.149073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.44701</td>\n",
       "      <td>0.188573</td>\n",
       "      <td>13.274385</td>\n",
       "      <td>18.837877</td>\n",
       "      <td>0.912276</td>\n",
       "      <td>1.189181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging SVR</th>\n",
       "      <td>0.44708</td>\n",
       "      <td>0.193568</td>\n",
       "      <td>13.751856</td>\n",
       "      <td>18.723399</td>\n",
       "      <td>0.912218</td>\n",
       "      <td>1.185515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.166873</td>\n",
       "      <td>0.090677</td>\n",
       "      <td>17.585576</td>\n",
       "      <td>19.54868</td>\n",
       "      <td>1.119756</td>\n",
       "      <td>1.258874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.892246</td>\n",
       "      <td>0.242856</td>\n",
       "      <td>6.337504</td>\n",
       "      <td>17.75722</td>\n",
       "      <td>0.402702</td>\n",
       "      <td>1.148716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.156318</td>\n",
       "      <td>0.284894</td>\n",
       "      <td>18.755004</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>1.212586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.972617</td>\n",
       "      <td>0.197541</td>\n",
       "      <td>3.043187</td>\n",
       "      <td>18.487144</td>\n",
       "      <td>0.203005</td>\n",
       "      <td>1.182591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Train_R2    Val_R2 Train_MAPE   Val_MAPE  \\\n",
       "Linear Regression          0.252533  0.238291  16.569106  17.485227   \n",
       "Bagging Linear Regression  0.257351  0.242384   16.64001  17.588544   \n",
       "SVR                         0.44701  0.188573  13.274385  18.837877   \n",
       "Bagging SVR                 0.44708  0.193568  13.751856  18.723399   \n",
       "Decision Tree              0.166873  0.090677  17.585576   19.54868   \n",
       "Random Forest              0.892246  0.242856   6.337504   17.75722   \n",
       "XGBoost                    0.999689  0.156318   0.284894  18.755004   \n",
       "LightGBM                   0.972617  0.197541   3.043187  18.487144   \n",
       "\n",
       "                          Train_RMSE  Val_RMSE  \n",
       "Linear Regression            1.06063  1.152173  \n",
       "Bagging Linear Regression   1.057206  1.149073  \n",
       "SVR                         0.912276  1.189181  \n",
       "Bagging SVR                 0.912218  1.185515  \n",
       "Decision Tree               1.119756  1.258874  \n",
       "Random Forest               0.402702  1.148716  \n",
       "XGBoost                     0.021644  1.212586  \n",
       "LightGBM                    0.203005  1.182591  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=['Linear Regression', 'Bagging Linear Regression', 'SVR', 'Bagging SVR', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM'],\n",
    "                           columns=['Train_R2', 'Val_R2', 'Train_MAPE', 'Val_MAPE', 'Train_RMSE', 'Val_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR()\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Bagging Linear Regression': BaggingRegressor(base_reg_lr, n_estimators=30, random_state=123),\n",
    "    'SVR': SVR(),\n",
    "    'Bagging SVR': BaggingRegressor(base_reg_svr, n_estimators=30, random_state=123),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=123, max_depth=3, min_samples_leaf=0.13),\n",
    "    'Random Forest': RandomForestRegressor(random_state=123),\n",
    "    'XGBoost': XGBRegressor(random_state=123),\n",
    "    'LightGBM': LGBMRegressor(random_state=123)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the training set\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    train_predictions = model.predict(X_train_sample)\n",
    "    train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "    train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "    val_r2 = r2_score(y_val, val_predictions)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "    val_mape = mean_absolute_percentage_error(y_val, val_predictions)\n",
    "    \n",
    "    results_df.loc[model_name] = [train_r2, val_r2, train_mape, val_mape, train_rmse, val_rmse]\n",
    "\n",
    "display(results_df.sort_values(by='Val_MAPE', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Val_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Val_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting Regressor</th>\n",
       "      <td>0.855406</td>\n",
       "      <td>0.211744</td>\n",
       "      <td>7.285072</td>\n",
       "      <td>18.239054</td>\n",
       "      <td>0.46649</td>\n",
       "      <td>1.172079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train_R2    Val_R2 Train_MAPE   Val_MAPE Train_RMSE  \\\n",
       "Voting Regressor  0.855406  0.211744   7.285072  18.239054    0.46649   \n",
       "\n",
       "                  Val_RMSE  \n",
       "Voting Regressor  1.172079  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index=['Voting Regressor'],\n",
    "                           columns=['Train_R2', 'Val_R2', 'Train_MAPE', 'Val_MAPE', 'Train_RMSE', 'Val_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR()\n",
    "\n",
    "models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, n_estimators=30, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, n_estimators=30, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(random_state=123))\n",
    "]\n",
    "\n",
    "voting_regressor = VotingRegressor(models)\n",
    "\n",
    "# Fit the model on the training set\n",
    "voting_regressor.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = voting_regressor.predict(X_train_sample)\n",
    "train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_predictions = voting_regressor.predict(X_val)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "val_mape = mean_absolute_percentage_error(y_val, val_predictions)\n",
    "\n",
    "results_df.loc['Voting Regressor'] = [train_r2, val_r2, train_mape, val_mape, train_rmse, val_rmse]\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Test_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking Regressor</th>\n",
       "      <td>0.698237</td>\n",
       "      <td>0.25451</td>\n",
       "      <td>10.580024</td>\n",
       "      <td>17.603045</td>\n",
       "      <td>0.673909</td>\n",
       "      <td>1.139841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Train_R2  Test_R2 Train_MAPE  Test_MAPE Train_RMSE  \\\n",
       "Stacking Regressor  0.698237  0.25451  10.580024  17.603045   0.673909   \n",
       "\n",
       "                   Test_RMSE  \n",
       "Stacking Regressor  1.139841  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index=['Stacking Regressor'],\n",
    "                           columns=['Train_R2', 'Test_R2', 'Train_MAPE', 'Test_MAPE', 'Train_RMSE', 'Test_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR()\n",
    "\n",
    "base_models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, n_estimators=30, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, n_estimators=30, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(random_state=123))\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Fit the model on the training set\n",
    "stacking_regressor.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = stacking_regressor.predict(X_train_sample)\n",
    "train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "test_predictions = stacking_regressor.predict(X_val)\n",
    "test_r2 = r2_score(y_val, test_predictions)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_val, test_predictions))\n",
    "test_mape = mean_absolute_percentage_error(y_val, test_predictions)\n",
    "\n",
    "results_df.loc['Stacking Regressor'] = [train_r2, test_r2, train_mape, test_mape, train_rmse, test_rmse]\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 30)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSS_vt = SequentialFeatureSelector(\n",
    "#     RandomForestRegressor(random_state=123),\n",
    "#     k_features=(1,30),\n",
    "#     forward=True,\n",
    "#     verbose=2,\n",
    "#     cv=5,\n",
    "#     scoring='neg_mean_absolute_percentage_error',\n",
    "#     n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'citric acid',\n",
       " 'feat01',\n",
       " 'feat04',\n",
       " 'feat07',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'total sulfur dioxide',\n",
       " 'volatile acidity',\n",
       " 'chlorides_Q1',\n",
       " 'chlorides_Q2',\n",
       " 'chlorides_Q3',\n",
       " 'chlorides_Q4',\n",
       " 'residual sugar_Q1',\n",
       " 'residual sugar_Q2',\n",
       " 'residual sugar_Q3',\n",
       " 'residual sugar_Q4',\n",
       " 'sulphates_Q1',\n",
       " 'sulphates_Q2',\n",
       " 'sulphates_Q3',\n",
       " 'sulphates_Q4']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(FSS_vt.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names = ['alcohol',\n",
    " 'citric acid',\n",
    " 'feat01',\n",
    " 'feat04',\n",
    " 'feat07',\n",
    " 'free sulfur dioxide',\n",
    " 'pH',\n",
    " 'total sulfur dioxide',\n",
    " 'volatile acidity',\n",
    " 'chlorides_Q1',\n",
    " 'chlorides_Q2',\n",
    " 'chlorides_Q3',\n",
    " 'chlorides_Q4',\n",
    " 'residual sugar_Q1',\n",
    " 'residual sugar_Q2',\n",
    " 'residual sugar_Q3',\n",
    " 'residual sugar_Q4',\n",
    " 'sulphates_Q1',\n",
    " 'sulphates_Q2',\n",
    " 'sulphates_Q3',\n",
    " 'sulphates_Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[selected_feature_names]\n",
    "X_test = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 80 is smaller than n_iter=100. Running 80 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 20, 'max_samples': 0.5, 'max_features': 1.0}\n",
      "RMSE: RandomizedSearchCV 1.0510461246277991\n",
      "MAPE: RandomizedSearchCV 15.407364490220651\n",
      "R2: RandomizedSearchCV 0.16162969028701635\n"
     ]
    }
   ],
   "source": [
    "# Base Linear Regression model\n",
    "base_model = LinearRegression()\n",
    "\n",
    "# Bagging Regressor with Linear Regression as base estimator\n",
    "bagging_reg = BaggingRegressor(base_model, random_state=123)\n",
    "\n",
    "# Hyperparameter grid for Bagging Regressor\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50],\n",
    "    'max_samples': [0.5, 0.7, 0.9, 1.0],\n",
    "    'max_features': [0.5, 0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "random_search_bagging = RandomizedSearchCV(\n",
    "    estimator=bagging_reg,\n",
    "    param_distributions=params,\n",
    "    n_iter=100,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_bagging.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters:\", random_search_bagging.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = random_search_bagging.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"RMSE:\", random_search_bagging.__class__.__name__, rmse)\n",
    "print(\"MAPE:\", random_search_bagging.__class__.__name__, mape)\n",
    "print(\"R2:\", random_search_bagging.__class__.__name__, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_bagging_lr = {'n_estimators': 20, 'max_samples': 0.5, 'max_features': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 80 is smaller than n_iter=100. Running 80 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Hyperparameters for SVR: {'kernel': 'linear', 'gamma': 'scale', 'epsilon': 0.1, 'C': 1}\n",
      "Best Hyperparameters for Bagging Regressor: {'n_estimators': 20, 'max_samples': 1.0, 'max_features': 1.0}\n",
      "RMSE: RandomizedSearchCV 1.050015568641571\n",
      "MAPE: RandomizedSearchCV 15.385464547488878\n",
      "R2: RandomizedSearchCV 0.16327293685643185\n"
     ]
    }
   ],
   "source": [
    "base_model = SVR()\n",
    "\n",
    "# Hyperparameter grid for svr\n",
    "params_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'epsilon': [0.1, 0.2, 0.5],\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for Bagging Regressor\n",
    "params_bagging_regressor = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50],\n",
    "    'max_samples': [0.5, 0.7, 0.9, 1.0],\n",
    "    'max_features': [0.5, 0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning for SVR\n",
    "random_search_svr = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=params_svr,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_error',  \n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_svr.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters for SVR\n",
    "best_params_svr = random_search_svr.best_params_\n",
    "\n",
    "# Base SVR model with optimized hyperparameters\n",
    "base_model_optimized = SVR(**best_params_svr)\n",
    "\n",
    "bagging_reg = BaggingRegressor(base_model_optimized, random_state=123)\n",
    "random_search_bagging = RandomizedSearchCV(\n",
    "    estimator=bagging_reg,\n",
    "    param_distributions=params_bagging_regressor,\n",
    "    n_iter=100,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_bagging.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters for SVR:\", best_params_svr)\n",
    "print(\"Best Hyperparameters for Bagging Regressor:\", random_search_bagging.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = random_search_bagging.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"RMSE:\", random_search_bagging.__class__.__name__, rmse)\n",
    "print(\"MAPE:\", random_search_bagging.__class__.__name__, mape)\n",
    "print(\"R2:\", random_search_bagging.__class__.__name__, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_svr = {'kernel': 'linear', 'gamma': 'scale', 'epsilon': 0.1, 'C': 1}\n",
    "best_params_bagging_svr = {'n_estimators': 20, 'max_samples': 1.0, 'max_features': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 270 is smaller than n_iter=500. Running 270 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Decision Tree Regressor: {'splitter': 'best', 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 5}\n",
      "RMSE: RandomizedSearchCV 1.1262187295836594\n",
      "MAPE: RandomizedSearchCV 16.645095835031466\n",
      "R2: RandomizedSearchCV 0.037417791290353386\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "    'splitter': ['best', 'random'],\n",
    "}\n",
    "\n",
    "\n",
    "random_search_decision_tree = RandomizedSearchCV(\n",
    "    estimator=decision_tree,\n",
    "    param_distributions=params,\n",
    "    n_iter=500,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters for Decision Tree Regressor:\", random_search_decision_tree.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = random_search_decision_tree.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "\n",
    "print(\"RMSE:\", random_search_decision_tree.__class__.__name__, rmse)\n",
    "print(\"MAPE:\", random_search_decision_tree.__class__.__name__, mape)\n",
    "print(\"R2:\", random_search_decision_tree.__class__.__name__, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_decision_tree = {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Random Forest: {'n_estimators': 200, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': False}\n",
      "RMSE: RandomizedSearchCV 1.0143390820791494\n",
      "MAPE: RandomizedSearchCV 15.120374527396097\n",
      "R2: RandomizedSearchCV 0.21916610505834766\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "\n",
    "random_search_random_forest = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_random_forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters for Random Forest:\", random_search_random_forest.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = random_search_random_forest.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"RMSE:\", random_search_random_forest.__class__.__name__, rmse)\n",
    "print(\"MAPE:\", random_search_random_forest.__class__.__name__, mape)\n",
    "print(\"R2:\", random_search_random_forest.__class__.__name__, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = {'n_estimators': 200, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for XGBoost: {'subsample': 0.5, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.5}\n",
      "RMSE: RandomizedSearchCV 1.024684619324475\n",
      "MAPE: RandomizedSearchCV 15.295918861707545\n",
      "R2: RandomizedSearchCV 0.20315697762011253\n"
     ]
    }
   ],
   "source": [
    "base_model = XGBRegressor()\n",
    "\n",
    "params_xgboost = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "    'reg_alpha': [0.0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0.0, 0.1, 0.5, 1.0],\n",
    "    'min_child_weight': [0, 1, 2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "random_search_xgboost = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=params_xgboost,\n",
    "    n_iter=100,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search_xgboost.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters for XGBoost:\", random_search_xgboost.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = random_search_xgboost.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"RMSE:\", random_search_xgboost.__class__.__name__, rmse)\n",
    "print(\"MAPE:\", random_search_xgboost.__class__.__name__, mape)\n",
    "print(\"R2:\", random_search_xgboost.__class__.__name__, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {'subsample': 0.5, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Val_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Val_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.252533</td>\n",
       "      <td>0.238291</td>\n",
       "      <td>16.569106</td>\n",
       "      <td>17.485227</td>\n",
       "      <td>1.06063</td>\n",
       "      <td>1.152173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Linear Regression</th>\n",
       "      <td>0.243775</td>\n",
       "      <td>0.218073</td>\n",
       "      <td>16.78885</td>\n",
       "      <td>17.830834</td>\n",
       "      <td>1.066825</td>\n",
       "      <td>1.167364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.44701</td>\n",
       "      <td>0.188573</td>\n",
       "      <td>13.274385</td>\n",
       "      <td>18.837877</td>\n",
       "      <td>0.912276</td>\n",
       "      <td>1.189181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging SVR</th>\n",
       "      <td>0.249931</td>\n",
       "      <td>0.227124</td>\n",
       "      <td>16.689595</td>\n",
       "      <td>17.844515</td>\n",
       "      <td>1.062474</td>\n",
       "      <td>1.160588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.281782</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>16.290088</td>\n",
       "      <td>19.370982</td>\n",
       "      <td>1.039671</td>\n",
       "      <td>1.250513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.861683</td>\n",
       "      <td>0.237578</td>\n",
       "      <td>6.893089</td>\n",
       "      <td>17.88685</td>\n",
       "      <td>0.456253</td>\n",
       "      <td>1.152712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.468477</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>14.068725</td>\n",
       "      <td>17.415053</td>\n",
       "      <td>0.894394</td>\n",
       "      <td>1.148489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Train_R2    Val_R2 Train_MAPE   Val_MAPE  \\\n",
       "Linear Regression          0.252533  0.238291  16.569106  17.485227   \n",
       "Bagging Linear Regression  0.243775  0.218073   16.78885  17.830834   \n",
       "SVR                         0.44701  0.188573  13.274385  18.837877   \n",
       "Bagging SVR                0.249931  0.227124  16.689595  17.844515   \n",
       "Decision Tree              0.281782  0.102716  16.290088  19.370982   \n",
       "Random Forest              0.861683  0.237578   6.893089   17.88685   \n",
       "XGBoost                    0.468477  0.243154  14.068725  17.415053   \n",
       "\n",
       "                          Train_RMSE  Val_RMSE  \n",
       "Linear Regression            1.06063  1.152173  \n",
       "Bagging Linear Regression   1.066825  1.167364  \n",
       "SVR                         0.912276  1.189181  \n",
       "Bagging SVR                 1.062474  1.160588  \n",
       "Decision Tree               1.039671  1.250513  \n",
       "Random Forest               0.456253  1.152712  \n",
       "XGBoost                     0.894394  1.148489  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index=['Linear Regression', 'Bagging Linear Regression', 'SVR', 'Bagging SVR', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
    "                           columns=['Train_R2', 'Val_R2', 'Train_MAPE', 'Val_MAPE', 'Train_RMSE', 'Val_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR(**best_params_svr)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Bagging Linear Regression': BaggingRegressor(base_reg_lr, **best_params_bagging_lr, random_state=123),\n",
    "    'SVR': SVR(),\n",
    "    'Bagging SVR': BaggingRegressor(base_reg_svr, **best_params_bagging_svr, random_state=123),\n",
    "    'Decision Tree': DecisionTreeRegressor(**best_params_decision_tree, random_state=123,),\n",
    "    'Random Forest': RandomForestRegressor(**best_params_rf, random_state=123),\n",
    "    'XGBoost': XGBRegressor(**best_params_xgb, random_state=123)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Fit each model on the training set\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    # Evaluate each model on the training set\n",
    "    train_predictions = model.predict(X_train_sample)\n",
    "    train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "    train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "    \n",
    "    # Evaluate each model on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "    val_r2 = r2_score(y_val, val_predictions)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "    val_mape = mean_absolute_percentage_error(y_val, val_predictions)\n",
    "    \n",
    "    # Store results in the DataFrame\n",
    "    results_df.loc[model_name] = [train_r2, val_r2, train_mape, val_mape, train_rmse, val_rmse]\n",
    "\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Val_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Val_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting Regressor</th>\n",
       "      <td>0.490569</td>\n",
       "      <td>0.250177</td>\n",
       "      <td>13.771388</td>\n",
       "      <td>17.530071</td>\n",
       "      <td>0.87561</td>\n",
       "      <td>1.143148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train_R2    Val_R2 Train_MAPE   Val_MAPE Train_RMSE  \\\n",
       "Voting Regressor  0.490569  0.250177  13.771388  17.530071    0.87561   \n",
       "\n",
       "                  Val_RMSE  \n",
       "Voting Regressor  1.143148  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index=['Voting Regressor'],\n",
    "                           columns=['Train_R2', 'Val_R2', 'Train_MAPE', 'Val_MAPE', 'Train_RMSE', 'Val_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR(**best_params_svr)\n",
    "\n",
    "# Define individual models\n",
    "models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, **best_params_bagging_lr, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, **best_params_bagging_svr, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(**best_params_decision_tree, random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(**best_params_rf, random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(**best_params_xgb, random_state=123))\n",
    "]\n",
    "\n",
    "# Create Voting Regressor\n",
    "voting_regressor = VotingRegressor(models)\n",
    "\n",
    "# Fit the model on the training set\n",
    "voting_regressor.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = voting_regressor.predict(X_train_sample)\n",
    "train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_predictions = voting_regressor.predict(X_val)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "val_mape = mean_absolute_percentage_error(y_val, val_predictions)\n",
    "\n",
    "results_df.loc['Voting Regressor'] = [train_r2, val_r2, train_mape, val_mape, train_rmse, val_rmse]\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>Train_MAPE</th>\n",
       "      <th>Test_MAPE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking Regressor</th>\n",
       "      <td>0.825659</td>\n",
       "      <td>0.25858</td>\n",
       "      <td>7.707027</td>\n",
       "      <td>17.502536</td>\n",
       "      <td>0.512233</td>\n",
       "      <td>1.136725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Train_R2  Test_R2 Train_MAPE  Test_MAPE Train_RMSE  \\\n",
       "Stacking Regressor  0.825659  0.25858   7.707027  17.502536   0.512233   \n",
       "\n",
       "                   Test_RMSE  \n",
       "Stacking Regressor  1.136725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index=['Stacking Regressor'],\n",
    "                           columns=['Train_R2', 'Test_R2', 'Train_MAPE', 'Test_MAPE', 'Train_RMSE', 'Test_RMSE'])\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR(**best_params_svr)\n",
    "\n",
    "base_models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, **best_params_bagging_lr, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, **best_params_bagging_svr, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(**best_params_decision_tree, random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(**best_params_rf, random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(**best_params_xgb, random_state=123))\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Fit the model on the training set\n",
    "stacking_regressor.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = stacking_regressor.predict(X_train_sample)\n",
    "train_r2 = r2_score(y_train_sample, train_predictions)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_sample, train_predictions))\n",
    "train_mape = mean_absolute_percentage_error(y_train_sample, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "test_predictions = stacking_regressor.predict(X_val)\n",
    "test_r2 = r2_score(y_val, test_predictions)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_val, test_predictions))\n",
    "test_mape = mean_absolute_percentage_error(y_val, test_predictions)\n",
    "\n",
    "results_df.loc['Stacking Regressor'] = [train_r2, test_r2, train_mape, test_mape, train_rmse, test_rmse]\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method _BaseHeterogeneousEnsemble.get_params of StackingRegressor(estimators=[('Bagging Linear Regression',\n",
      "                               BaggingRegressor(estimator=LinearRegression(),\n",
      "                                                max_samples=0.5,\n",
      "                                                n_estimators=20,\n",
      "                                                random_state=123)),\n",
      "                              ('Bagging SVR',\n",
      "                               BaggingRegressor(estimator=SVR(C=1,\n",
      "                                                              kernel='linear'),\n",
      "                                                n_estimators=20,\n",
      "                                                random_state=123)),\n",
      "                              ('Decision Tree',\n",
      "                               DecisionTreeRegressor(max_depth=5,\n",
      "                                                     max_features='log2',\n",
      "                                                     min_samples_leaf=4,\n",
      "                                                     random...\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=0.05, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=3,\n",
      "                                            max_leaves=None, min_child_weight=1,\n",
      "                                            missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=100, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            predictor=None, random_state=123, ...))],\n",
      "                  final_estimator=LinearRegression())>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(stacking_regressor.get_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking Regressor</th>\n",
       "      <td>1.062143</td>\n",
       "      <td>16.528961</td>\n",
       "      <td>0.248389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RMSE       MAPE        R2\n",
       "Stacking Regressor  1.062143  16.528961  0.248389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(['quality', 'id', 'density', 'feat02', 'feat03', 'feat05', 'feat06', 'feat08', 'feat09', 'feat10', 'fixed acidity'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "cols_to_scale = X.columns.drop(['chlorides', 'residual sugar', 'sulphates'])\n",
    "\n",
    "cols_to_encode = ['chlorides', 'residual sugar', 'sulphates']\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "categoric_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_to_scale),\n",
    "        ('cat', categoric_transformer, cols_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR(**best_params_svr)\n",
    "\n",
    "base_models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, **best_params_bagging_lr, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, **best_params_bagging_svr, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(**best_params_decision_tree, random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(**best_params_rf, random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(**best_params_xgb, random_state=123))\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=base_reg_lr)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', stacking_regressor)\n",
    "    ] \n",
    ")\n",
    "\n",
    "def mape_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return mean_absolute_percentage_error(y, y_pred)\n",
    "\n",
    "cv_rmse = cross_val_score(pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_mape = cross_val_score(pipeline, X, y, cv=5, scoring=mape_scorer)\n",
    "cv_r2 = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "resutls_df2 = pd.DataFrame(index=['Stacking Regressor'],\n",
    "                            columns=['RMSE', 'MAPE', 'R2'])\n",
    "\n",
    "resutls_df2.loc['Stacking Regressor'] = [-cv_rmse.mean(), cv_mape.mean(), cv_r2.mean()]\n",
    "display(resutls_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking Regressor</th>\n",
       "      <td>1.062143</td>\n",
       "      <td>16.528961</td>\n",
       "      <td>0.248389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Regressor</th>\n",
       "      <td>1.08101</td>\n",
       "      <td>16.854866</td>\n",
       "      <td>0.221863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RMSE       MAPE        R2\n",
       "Stacking Regressor  1.062143  16.528961  0.248389\n",
       "Voting Regressor     1.08101  16.854866  0.221863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(['quality', 'id', 'density', 'feat02', 'feat03', 'feat05', 'feat06', 'feat08', 'feat09', 'feat10', 'fixed acidity'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "cols_to_scale = X.columns.drop(['chlorides', 'residual sugar', 'sulphates'])\n",
    "\n",
    "cols_to_encode = ['chlorides', 'residual sugar', 'sulphates']\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "categoric_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_to_scale),\n",
    "        ('cat', categoric_transformer, cols_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_reg_lr = LinearRegression()\n",
    "base_reg_svr = SVR(**best_params_svr)\n",
    "\n",
    "models = [\n",
    "    ('Bagging Linear Regression', BaggingRegressor(base_reg_lr, **best_params_bagging_lr, random_state=123)),\n",
    "    ('Bagging SVR', BaggingRegressor(base_reg_svr, **best_params_bagging_svr, random_state=123)),\n",
    "    ('Decision Tree', DecisionTreeRegressor(**best_params_decision_tree, random_state=123)),\n",
    "    ('Random Forest', RandomForestRegressor(**best_params_rf, random_state=123)),\n",
    "    ('XGBoost', XGBRegressor(**best_params_xgb, random_state=123))\n",
    "]\n",
    "\n",
    "voting_regressor = VotingRegressor(models)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', voting_regressor)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def mape_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return mean_absolute_percentage_error(y, y_pred)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_rmse = cross_val_score(pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_mape = cross_val_score(pipeline, X, y, cv=5, scoring=mape_scorer)\n",
    "cv_r2 = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "resutls_df2.loc['Voting Regressor'] = [-cv_rmse.mean(), cv_mape.mean(), cv_r2.mean()]\n",
    "display(resutls_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking Regressor</th>\n",
       "      <td>1.062143</td>\n",
       "      <td>16.528961</td>\n",
       "      <td>0.248389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Regressor</th>\n",
       "      <td>1.08101</td>\n",
       "      <td>16.854866</td>\n",
       "      <td>0.221863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.062052</td>\n",
       "      <td>16.545573</td>\n",
       "      <td>0.248867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RMSE       MAPE        R2\n",
       "Stacking Regressor  1.062143  16.528961  0.248389\n",
       "Voting Regressor     1.08101  16.854866  0.221863\n",
       "Random Forest       1.062052  16.545573  0.248867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(['quality', 'id', 'density', 'feat02', 'feat03', 'feat05', 'feat06', 'feat08', 'feat09', 'feat10', 'fixed acidity'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "cols_to_scale = X.columns.drop(['chlorides', 'residual sugar', 'sulphates'])\n",
    "\n",
    "cols_to_encode = ['chlorides', 'residual sugar', 'sulphates']\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "categoric_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_to_scale),\n",
    "        ('cat', categoric_transformer, cols_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(**best_params_rf, random_state=123)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', rf)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def mape_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return mean_absolute_percentage_error(y, y_pred)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_rmse = cross_val_score(pipeline, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_mape = cross_val_score(pipeline, X, y, cv=5, scoring=mape_scorer)\n",
    "cv_r2 = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "resutls_df2.loc['Random Forest'] = [-cv_rmse.mean(), cv_mape.mean(), cv_r2.mean()]\n",
    "display(resutls_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filsz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.196783</td>\n",
       "      <td>0.869905</td>\n",
       "      <td>15.120640</td>\n",
       "      <td>1.093976</td>\n",
       "      <td>0.091745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.211767</td>\n",
       "      <td>0.869968</td>\n",
       "      <td>15.121738</td>\n",
       "      <td>1.100803</td>\n",
       "      <td>0.080374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.317702</td>\n",
       "      <td>0.914636</td>\n",
       "      <td>15.898148</td>\n",
       "      <td>1.147912</td>\n",
       "      <td>-0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.321127</td>\n",
       "      <td>0.916945</td>\n",
       "      <td>15.938294</td>\n",
       "      <td>1.149403</td>\n",
       "      <td>-0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.350760</td>\n",
       "      <td>0.929254</td>\n",
       "      <td>16.152239</td>\n",
       "      <td>1.162222</td>\n",
       "      <td>-0.025110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.351293</td>\n",
       "      <td>0.929452</td>\n",
       "      <td>16.155680</td>\n",
       "      <td>1.162451</td>\n",
       "      <td>-0.025514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.410950</td>\n",
       "      <td>0.951373</td>\n",
       "      <td>16.536717</td>\n",
       "      <td>1.187834</td>\n",
       "      <td>-0.070789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.406377</td>\n",
       "      <td>0.955347</td>\n",
       "      <td>16.605792</td>\n",
       "      <td>1.185908</td>\n",
       "      <td>-0.067319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.499528</td>\n",
       "      <td>0.978969</td>\n",
       "      <td>17.016391</td>\n",
       "      <td>1.224552</td>\n",
       "      <td>-0.138012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr activation_func       mse       mae       mape      rmse        r2\n",
       "1  0.001            tanh  1.196783  0.869905  15.120640  1.093976  0.091745\n",
       "3  0.010            relu  1.211767  0.869968  15.121738  1.100803  0.080374\n",
       "4  0.010            tanh  1.317702  0.914636  15.898148  1.147912 -0.000022\n",
       "5  0.010         sigmoid  1.321127  0.916945  15.938294  1.149403 -0.002621\n",
       "8  0.100         sigmoid  1.350760  0.929254  16.152239  1.162222 -0.025110\n",
       "6  0.100            relu  1.351293  0.929452  16.155680  1.162451 -0.025514\n",
       "7  0.100            tanh  1.410950  0.951373  16.536717  1.187834 -0.070789\n",
       "0  0.001            relu  1.406377  0.955347  16.605792  1.185908 -0.067319\n",
       "2  0.001         sigmoid  1.499528  0.978969  17.016391  1.224552 -0.138012"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['quality', 'id', 'density', 'feat02', 'feat03', 'feat05', 'feat06', 'feat08', 'feat09', 'feat10', 'fixed acidity'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "cols_to_scale = X.columns.drop(['chlorides', 'residual sugar', 'sulphates'])\n",
    "\n",
    "cols_to_encode = ['chlorides', 'residual sugar', 'sulphates']\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "categoric_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_to_scale),\n",
    "        ('cat', categoric_transformer, cols_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "columns = cols_to_scale.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out(cols_to_encode).tolist()\n",
    "X_train_scaled = pd.DataFrame(X_train, columns=columns)\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test, columns=columns)\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "activation_functions = ['relu', 'tanh', 'sigmoid']\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for activation_func in activation_functions:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation=activation_func))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64, activation=activation_func))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(32, activation=activation_func))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(16, activation=activation_func))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=300, batch_size=64, validation_split=0.2, verbose=0)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        mape = mean_absolute_error(y_test, predictions) / abs(y_test).mean() * 100\n",
    "        rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'activation_func': activation_func,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values('mape', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
